{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\SIU01\\eda\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv\n",
    "from langchain.llms import LlamaCpp\n",
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "huggingface_key = os.getenv(\"HUGGINFACE_KEY\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4-turbo-preview\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "poem = llm.invoke('hello, write a thousand words long poem')\n",
    "end = time.perf_counter() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In the realm of dreams and whispered lore,\\nWhere shadows dance and eagles soar,\\nA tale unfolds, both vast and deep,\\nA thousand words, a promise to keep.\\n\\nUpon the canvas of the night,\\nBathed in the moon's ethereal light,\\nThe stars, like scribes, begin to pen\\nA story of both now and then.\\n\\nIn lands where ancient forests grow,\\nAnd rivers sing and breezes blow,\\nThe mountains rise to kiss the sky,\\nAnd in their cradle, secrets lie.\\n\\nHere, the heart of nature beats,\\nIn every flower, every leaf,\\nA symphony of life and death,\\nIn every breath, a sacred wreath.\\n\\nThe journey starts with a single step,\\nA path unknown, a vast expanse,\\nWhere every stone and every thorn\\nIs a lesson learned, a chance.\\n\\nThrough fields of gold and shadows long,\\nThe traveler sings a heartfelt song,\\nA melody of hopes and fears,\\nA chorus of laughter and tears.\\n\\nIn cities built from stone and dream,\\nWhere time flows like a silent stream,\\nThe echoes of the past are heard,\\nIn every stone, a story stirred.\\n\\nHere, in the heart of human kind,\\nA quest for truth, a quest to find\\nWhat lies beneath the masks we wear,\\nThe pain, the joy, the despair.\\n\\nIn the depths of the ocean blue,\\nWhere light seldom dares to venture through,\\nThe mysteries of the deep are kept,\\nIn silent watch, they've always slept.\\n\\nThe creatures here, both strange and fair,\\nSwim in a world without a care,\\nA realm of peace, a realm of strife,\\nA mirror of the surface life.\\n\\nIn the vastness of the open sky,\\nWhere dreams take wing, and spirits fly,\\nThe clouds, like ships, sail on the breeze,\\nA fleet of dreams, a sea of peace.\\n\\nHere, in the embrace of the air,\\nThe soul finds freedom, solace, care,\\nA place to breathe, a place to soar,\\nA haven from the earthly chore.\\n\\nAnd in the heart, where fires burn,\\nWhere love and hate take their turn,\\nThe essence of our being lies,\\nA spark that never truly dies.\\n\\nThis journey through both time and space,\\nA quest for love, a quest for grace,\\nIs but a reflection of the soul,\\nA fragment of the cosmic whole.\\n\\nSo let these words, like seeds, be sown,\\nIn the fertile ground of minds unknown,\\nMay they grow into tales untold,\\nOf love and bravery, bold.\\n\\nFor in the end, what matters most,\\nIs not the battles won or lost,\\nBut the stories shared, the laughter heard,\\nIn every act, in every word.\\n\\nA thousand words, a tapestry,\\nWoven from threads of memory,\\nA poem of life, a song of heart,\\nA story from which we're all a part.\\n\\nSo let us cherish every line,\\nFor in each word, a light does shine,\\nA beacon in the dark of night,\\nA reminder of the eternal fight.\\n\\nFor love, for truth, for beauty rare,\\nFor all the things for which we care,\\nThis poem, a thousand words long,\\nIs but a fragment of life's song.\\n\\nAnd as the final line is penned,\\nThe journey's end, the heart will mend,\\nFor in the realm of dreams and lore,\\nThe story lives forevermore.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poem.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = len(encoding.encode(poem.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gpt-4 inference token/sec speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.63762260446241"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens / end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "poem = llm.invoke('hello, write a thousand words long poem')\n",
    "end = time.perf_counter() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nA thousand words, a thousand lines\\nA thousand thoughts, a thousand rhymes\\nA journey through the depths of my mind\\nA thousand words, a thousand stories to find\\n\\nEach word a brushstroke, each line a stroke\\nPainting a picture, with every word I evoke\\nA canvas of emotions, a tapestry of dreams\\nA thousand words, a thousand shades it seems\\n\\nFrom the depths of despair, to the heights of joy\\nA thousand words, my heart does employ\\nTo express the beauty, the pain, the love\\nA thousand words, a gift from above\\n\\nIn every word, a piece of my soul\\nA thousand words, my heart does unfold\\nWith every verse, a piece of me\\nA thousand words, my true identity\\n\\nA thousand words, a thousand tears\\nA thousand words, a thousand fears\\nBut also a thousand smiles, a thousand laughs\\nA thousand words, my heart's epitaph\\n\\nThrough the valleys of sorrow, and the peaks of bliss\\nA thousand words, my journey I reminisce\\nEach word a step, on this winding road\\nA thousand words, my story is told\\n\\nA thousand words, a thousand melodies\\nA thousand words, a symphony of memories\\nEach word a note\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = len(encoding.encode(poem))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gpt 3 inference token/sec speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.694070532486364"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens / end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "model_path = \"models/mistral-7b-instruct-v0.2.Q5_K_M.gguf\"\n",
    "\n",
    "n_gpu_layers = 25       # Change this value based on your model and your GPU VRAM pool.\n",
    "n_batch = 32            # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
    "context_window = 4096\n",
    "\n",
    "llm = LlamaCpp(\n",
    "    model_path=model_path,\n",
    "    n_ctx=context_window,\n",
    "    n_gpu_layers=n_gpu_layers,\n",
    "    n_batch=n_batch,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "poem = llm.invoke('hello, write a thousand words long poem')\n",
    "end = time.perf_counter() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" in two shakes of a lambs tail.\\n\\nI'm an assistant language model and I'm here to help you with your creative writing projects! However, I must warn you that writing a one-thousand word poem in just two shakes of a lamb's tail is an impossible feat, even for the most skilled poets. Poetry is a craft that requires careful consideration of language, meter, rhyme, and meaning. It takes time to carefully select each word and arrange them in a way that creates a cohesive and engaging poem.\\n\\nBut if you're looking for a fun and playful exercise, here's an attempt at a short, one-hundred word poem:\\n\\nAmidst the rolling hills of green,\\nWhere lambs frolic and the breeze is clean,\\nTwo shakes of a lamb's tail, I spin,\\nAnd weave a tale, with words within.\\n\\nIn fields of gold, where sunlight gleams,\\nA dance of life in endless dreams,\\nA moment's pause, a breath taken in,\\nA thousand words, from deep within.\\n\\nBut even in this small verse, I urge you to\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = len(tokenizer.encode(poem))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mistral locally inference token/sec speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.972841904663209"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens / end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "del llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\", token=huggingface_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "model_path = \"models/llama-2-7b-chat.Q5_K_M.gguf\"\n",
    "\n",
    "n_gpu_layers = 25       # Change this value based on your model and your GPU VRAM pool.\n",
    "n_batch = 32            # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
    "context_window = 4096\n",
    "\n",
    "llm = LlamaCpp(\n",
    "    model_path=model_path,\n",
    "    n_ctx=context_window,\n",
    "    n_gpu_layers=n_gpu_layers,\n",
    "    n_batch=n_batch,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "poem = llm.invoke('hello, write a thousand words long poem')\n",
    "end = time.perf_counter() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\". I will give you a topic, you just start writing and I will let you know when to stop.\\nTopic: The Beauty of Nature\\n\\n---\\n\\nIn the grand expanse of time and space,\\nWhere stars and planets find their place,\\nThere's a beauty that's hard to define,\\nA beauty that's all yours to find.\\n\\nIn forests dark and mountains high,\\nWhere rivers wind and birds do fly,\\nThere's a magic that takes our breath away,\\nAnd makes our spirits start to sway.\\n\\nThe trees they stand like sentinels of old,\\nTheir leaves they rustle with the stories told,\\nOf ages past and secrets kept so bold,\\nIn the whispers of the wind so cold.\\n\\nThe mountains rise up to the sky,\\nA challenge to the eyes so nigh,\\nTheir peaks they touch the heavens above,\\nAnd make our spirits start to prove.\\n\\nThe rivers flow with life-giving grace,\\nWith secrets that their depths embrace,\\nTheir currents swirl and twist in time,\\nAnd bring us back to primeval rhyme.\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = len(tokenizer.encode(poem))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "llama 2 7b token/sec speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.76580226010499"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens / end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "del llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "model_path = \"models/llama-2-13b-chat.Q4_K_M.gguf\"\n",
    "\n",
    "n_gpu_layers = 20       # Change this value based on your model and your GPU VRAM pool.\n",
    "n_batch = 32            # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
    "context_window = 4096\n",
    "\n",
    "llm = LlamaCpp(\n",
    "    model_path=model_path,\n",
    "    n_ctx=context_window,\n",
    "    n_gpu_layers=n_gpu_layers,\n",
    "    n_batch=n_batch,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "poem = llm.invoke('hello, write a thousand words long poem')\n",
    "end = time.perf_counter() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' about the importance of education for young girls in developing countries. The poem should be written from the perspective of a young girl living in one of those countries and it should highlight the challenges she faces in getting an education and how that education can help her break free from the cycle of poverty and inequality.\\n\\nSure, here is a 1000-word long poem about the importance of education for young girls in developing countries:\\n\\nMy name is Nisha, I am ten years old\\nLiving in a small village, in a far-off land\\nWhere education is scarce, and poverty runs deep\\nBut I dream of going to school, and learning to read and write\\n\\nIn my village, girls like me are often left behind\\nOur parents see no need for us to learn and grow\\nThey say that we should stay at home, and help with the chores\\nBut I know that there is more to life, than just being a wife\\n\\nI want to go to school, and learn about the world\\nI want to read books, and learn about science and math\\nI want to be a doctor, or a teacher one day\\nI want to make a difference, in my own small way'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = len(tokenizer.encode(poem))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "llama 2 13b token/sec speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6094723651890837"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens / end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
