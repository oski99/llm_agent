{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.llms import LlamaCpp\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_experimental.tools.python.tool import PythonAstREPLTool\n",
    "from langchain_openai import OpenAI, ChatOpenAI\n",
    "\n",
    "from custom_react_agent import create_react_agent\n",
    "from prompt_template import llama_pandas_template\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4-turbo-preview\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "# model_path = \"models/llama-2-7b-chat.Q5_K_M.gguf\"\n",
    "# model_path = \"models/llama-2-13b-chat.Q4_K_M.gguf\"\n",
    "model_path = \"models/mistral-7b-instruct-v0.2.Q5_K_M.gguf\"\n",
    "\n",
    "n_gpu_layers = 25       # Change this value based on your model and your GPU VRAM pool.\n",
    "n_batch = 32            # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
    "context_window = 4096\n",
    "\n",
    "llm = LlamaCpp(\n",
    "    model_path=model_path,\n",
    "    n_ctx=context_window,\n",
    "    n_gpu_layers=n_gpu_layers,\n",
    "    n_batch=n_batch,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/anonymized/student.csv')\n",
    "\n",
    "# in the shell all packages from this env are available\n",
    "shell = PythonAstREPLTool(locals={\"df\": df})\n",
    "\n",
    "shell.run(\n",
    "    \"import numpy as np; import matplotlib.pyplot as plt; import pandas as pd; import seaborn as sns\"\n",
    ")\n",
    "\n",
    "tools = [shell]\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"agent_scratchpad\", \"input\", \"tools\", \"dfhead\"],\n",
    "    template=llama_pandas_template,\n",
    ")\n",
    "\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo extract the top 5 highest values from the third column, I can sort the dataframe based on the third column in descending order and then select the top 5 values.\n",
      "Action: python_repl_ast\n",
      "Action Input: df['att_3'].nlargest(5)\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m46     22.0\n",
      "302    21.0\n",
      "114    20.0\n",
      "166    20.0\n",
      "228    20.0\n",
      "Name: att_3, dtype: float64\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer. \n",
      "Final Answer: The top 5 highest values from the third column are 22.0, 21.0, 20.0, 20.0, and 20.0.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "answer = agent_executor.invoke(\n",
    "    {\"input\": \"Extract the top 5 highest values from the third column.\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     att_3  att_7  att_8  att_13  att_14  att_15  att_24  att_25  att_26  \\\n",
      "227   17.0    2.0    3.0     2.0     1.0     0.0     3.0     3.0     3.0   \n",
      "42    15.0    4.0    2.0     1.0     4.0     0.0     3.0     3.0     3.0   \n",
      "256   19.0    1.0    1.0     1.0     3.0     2.0     4.0     1.0     3.0   \n",
      "182   16.0    2.0    2.0     2.0     4.0     0.0     5.0     3.0     5.0   \n",
      "56    16.0    1.0    3.0     1.0     2.0     3.0     4.0     3.0     5.0   \n",
      "..     ...    ...    ...     ...     ...     ...     ...     ...     ...   \n",
      "249   15.0    4.0    4.0     2.0     2.0     2.0     4.0     3.0     4.0   \n",
      "297   18.0    3.0    2.0     2.0     1.0     1.0     2.0     5.0     3.0   \n",
      "222   17.0    2.0    2.0     2.0     2.0     0.0     4.0     5.0     2.0   \n",
      "351   17.0    4.0    1.0     2.0     1.0     0.0     4.0     5.0     4.0   \n",
      "202   16.0    4.0    3.0     1.0     3.0     0.0     5.0     3.0     5.0   \n",
      "\n",
      "     att_27  ...  att_18_b  att_19_a  att_19_b  att_20_a  att_20_b  att_21_a  \\\n",
      "227     1.0  ...      True      True     False      True     False      True   \n",
      "42      1.0  ...     False      True     False      True     False      True   \n",
      "256     1.0  ...     False      True     False     False      True      True   \n",
      "182     1.0  ...      True     False      True     False      True      True   \n",
      "56      1.0  ...     False     False      True     False      True      True   \n",
      "..      ...  ...       ...       ...       ...       ...       ...       ...   \n",
      "249     2.0  ...      True      True     False      True     False      True   \n",
      "297     5.0  ...     False      True     False     False      True      True   \n",
      "222     1.0  ...      True     False      True      True     False      True   \n",
      "351     2.0  ...      True     False      True      True     False      True   \n",
      "202     1.0  ...      True      True     False      True     False      True   \n",
      "\n",
      "     att_21_b  att_22_a  att_22_b  att_23_a  \n",
      "227     False      True     False      True  \n",
      "42      False     False      True      True  \n",
      "256     False     False      True     False  \n",
      "182     False     False      True      True  \n",
      "56      False     False      True     False  \n",
      "..        ...       ...       ...       ...  \n",
      "249     False     False      True     False  \n",
      "297     False     False      True      True  \n",
      "222     False     False      True      True  \n",
      "351     False     False      True     False  \n",
      "202     False     False      True      True  \n",
      "\n",
      "[107 rows x 58 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tools[0].run('print(X_test)'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
